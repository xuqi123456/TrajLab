package whu.edu.cn.trajlab.query.query.basic;

import com.google.protobuf.ByteString;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.sql.SparkSession;
import whu.edu.cn.trajlab.base.util.SparkUtils;
import whu.edu.cn.trajlab.db.condition.AbstractQueryCondition;
import whu.edu.cn.trajlab.db.database.DataSet;
import whu.edu.cn.trajlab.db.database.Database;
import whu.edu.cn.trajlab.db.database.meta.IndexMeta;
import whu.edu.cn.trajlab.db.database.table.IndexTable;
import whu.edu.cn.trajlab.db.datatypes.ByteArray;
import whu.edu.cn.trajlab.db.index.RowKeyRange;
import org.apache.spark.api.java.JavaRDD;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import scala.NotImplementedError;
import whu.edu.cn.trajlab.base.trajectory.Trajectory;
import whu.edu.cn.trajlab.query.coprocessor.autogenerated.QueryCondition;

import java.io.IOException;
import java.util.ArrayList;
import java.util.List;

/**
 * @author xuqi
 * @date 2023/12/01
 */
public abstract class AbstractQuery {

  private static final Logger logger = LoggerFactory.getLogger(AbstractQuery.class);

  public DataSet dataSet;
  public IndexTable targetIndexTable;
  public AbstractQueryCondition abstractQueryCondition;

  public AbstractQuery(DataSet dataSet, AbstractQueryCondition abstractQueryCondition) {
    this.dataSet = dataSet;
    this.abstractQueryCondition = abstractQueryCondition;
  }

  protected AbstractQuery(
      IndexTable targetIndexTable, AbstractQueryCondition abstractQueryCondition)
      throws IOException {
    this.targetIndexTable = targetIndexTable;
    this.abstractQueryCondition = abstractQueryCondition;
  }

  /**
   * 基于查询条件与目标表, 获取要查询的row-key范围.
   *
   * @return
   */
  public List<RowKeyRange> getIndexRanges() throws IOException{
    setupTargetIndexTable();
    return targetIndexTable.getIndexMeta().getIndexStrategy().getScanRanges(abstractQueryCondition);
  }
  public List<RowKeyRange> getSplitIndexRanges() throws IOException{
    setupTargetIndexTable();
    return targetIndexTable.getIndexMeta().getIndexStrategy().getPartitionScanRanges(abstractQueryCondition);
  }

  public IndexTable getTargetIndexTable() {
    return targetIndexTable;
  }

  /**
   * Query <strong>all</strong> ranges that meets query request on target table.
   *
   * @return
   */
  public List<Trajectory> executeQuery() throws IOException{
    List<RowKeyRange> rowKeyRanges = getIndexRanges();
    return executeQuery(rowKeyRanges);
  }
  public abstract List<Trajectory> executeQuery(List<RowKeyRange> rowKeyRanges) throws IOException;
  public JavaRDD<Trajectory> getRDDQuery(SparkSession ss) throws IOException{
    List<RowKeyRange> indexRanges = getSplitIndexRanges();
    JavaSparkContext context = SparkUtils.getJavaSparkContext(ss);
    JavaRDD<RowKeyRange> rowKeyRangeJavaRDD = context.parallelize(indexRanges);

    return rowKeyRangeJavaRDD
            .groupBy(RowKeyRange::getShardKey)
            .flatMap(
                    iteratorPair -> {
                      // 对每个分区中的元素进行转换操作
                      List<RowKeyRange> result = new ArrayList<>();
                      for (RowKeyRange rowKeyRange : iteratorPair._2) {
                        result.add(rowKeyRange);
                      }
                      return executeQuery(result).iterator();
                    });
  };

  // 这里面能实现比较复杂的逻辑，比如根据数据的时空分布、主副索引的性能差异、查询条件对不同维度的侧重点，选择恰当的index。
  // 当下是一个最简单的逻辑：找到对应查询适合的索引，从里面选一个主索引，避免多次回表查询。
  public abstract IndexMeta findBestIndex();

  public abstract String getQueryInfo();

  protected void setupTargetIndexTable() throws IOException {
    if (targetIndexTable == null) {
      IndexMeta indexMeta = findBestIndex();
      logger.info(
          "Query [{}] will be executed on table: {}",
          getQueryInfo(),
          indexMeta.getIndexTableName());
      targetIndexTable = dataSet.getIndexTable(indexMeta);
    }
  }

  /** 类型转换 + 排序 */
  protected List<QueryCondition.Range> rowKeyRangeToProtoRange(List<RowKeyRange> rowKeyRanges) {
    List<QueryCondition.Range> ranges = new ArrayList<>();
    for (RowKeyRange rowKeyRange : rowKeyRanges) {
      QueryCondition.Range r =
          QueryCondition.Range.newBuilder()
              .setStart(ByteString.copyFrom(rowKeyRange.getStartKey().getBytes()))
              .setEnd(ByteString.copyFrom(rowKeyRange.getEndKey().getBytes()))
              .setContained(rowKeyRange.isValidate())
              .build();
      ranges.add(r);
    }

    ranges.sort(
        (o1, o2) -> {
          ByteArray o1Start = new ByteArray(o1.getStart().toByteArray());
          ByteArray o2Start = new ByteArray(o2.getStart().toByteArray());
          ByteArray o1End = new ByteArray(o1.getEnd().toByteArray());
          ByteArray o2End = new ByteArray(o2.getEnd().toByteArray());
          return o1Start.compareTo(o2Start) == 0
              ? o1End.compareTo(o2End)
              : o1Start.compareTo(o2Start);
        });
    return ranges;
  }
  public static AbstractQuery getQuery(String dataSetName, AbstractQueryCondition abstractQueryCondition) throws IOException {
    DataSet dataSet = getDataSet(dataSetName);
    switch (abstractQueryCondition.getInputType()){
      case SPATIAL:
        return new SpatialQuery(dataSet, abstractQueryCondition);
      case TEMPORAL:
        return new TemporalQuery(dataSet, abstractQueryCondition);
      case ID:
        return new IDQuery(dataSet, abstractQueryCondition);
      case ID_T:
        return new IDTemporalQuery(dataSet, abstractQueryCondition);
      case ST:
        return new SpatialTemporalQuery(dataSet, abstractQueryCondition);
      case DATASET:
        return new DataSetQuery(dataSet, abstractQueryCondition);
      default: throw new NotImplementedError();
    }
  }
  public static DataSet getDataSet(String dataSetName) throws IOException {
    Database instance = Database.getInstance();
    return instance.getDataSet(dataSetName);
  }
}
